\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@input{portadaTesis.aux}
\babel@aux{english}{}
\citation{handsonmachinelearning}
\citation{handsonmachinelearning}
\citation{VGGimg}
\citation{learningRates}
\citation{Vanishing}
\citation{parkinsonhistoria}
\citation{parkinson2002essay}
\citation{sveinbjornsdottir2016clinical}
\citation{frank2006approach}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{5}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Context}{5}{subsection.1.1}\protected@file@percent }
\citation{synapse}
\citation{handsonmachinelearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Objective}{7}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Document Structure}{8}{subsection.1.3}\protected@file@percent }
\citation{deeplearningygrabaciones}
\citation{belic2019artificial}
\citation{cnntoformantmeasures}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}State Of Art}{9}{subsection.1.4}\protected@file@percent }
\citation{handsonmachinelearning}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretical Foundations}{10}{section.2}\protected@file@percent }
\newlabel{sec:TheoreticalBases}{{2}{10}{Theoretical Foundations}{section.2}{}}
\citation{handsonmachinelearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Types of Machine Learning Systems }{11}{subsection.2.1}\protected@file@percent }
\citation{cortex58}
\citation{cortex59}
\citation{neocognitron}
\citation{handsonmachinelearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The CNN Model and VGG Architecture}{13}{subsection.2.2}\protected@file@percent }
\citation{handsonmachinelearning}
\citation{VGGinfo}
\citation{VGGimg}
\newlabel{ConvLayer}{{2.2}{14}{The CNN Model and VGG Architecture}{subsection.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Visual representation of the effects of convolution layers.\cite  {handsonmachinelearning}}}{14}{figure.1}\protected@file@percent }
\newlabel{MaxPoolLayer}{{2.2}{14}{The CNN Model and VGG Architecture}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visual representation of the effects of pooling layers. \cite  {handsonmachinelearning}}}{14}{figure.2}\protected@file@percent }
\newlabel{VGGArchitecture}{{2.2}{15}{The CNN Model and VGG Architecture}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visual representation of a VGG architecture. \cite  {VGGimg}}}{15}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Data Set Overview And Preprocessing}{16}{section.3}\protected@file@percent }
\newlabel{sec:Data}{{3}{16}{Data Set Overview And Preprocessing}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Cleaning The Data Set }{18}{subsection.3.1}\protected@file@percent }
\citation{normalization}
\citation{normalizationTechniques}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Normalizing The Data Set And Transforming Non Numerical Values }{20}{subsection.3.2}\protected@file@percent }
\newlabel{Feature02N}{{3.2}{20}{Normalizing The Data Set And Transforming Non Numerical Values}{subsection.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Histogram for a normalized attribute with outliers. Feature02}}{20}{figure.4}\protected@file@percent }
\newlabel{Feature24N}{{3.2}{21}{Normalizing The Data Set And Transforming Non Numerical Values}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Histogram for a normalized attribute with outliers. Feature24}}{21}{figure.5}\protected@file@percent }
\newlabel{Feature24NC}{{3.2}{21}{Normalizing The Data Set And Transforming Non Numerical Values}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Histogram for a normalized and clipped attribute. Feature24}}{21}{figure.6}\protected@file@percent }
\citation{datascienceZscore}
\citation{normalizationTechniques}
\citation{normalizeSkLearn}
\newlabel{Feature03Comparidson}{{3.2}{23}{Normalizing The Data Set And Transforming Non Numerical Values}{lstnumber.-5.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces width=50mm}}{23}{figure.7}\protected@file@percent }
\citation{dateTestsDefs}
\citation{handsonmachinelearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Splitting The Data Set}{24}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Generating The Labels}{26}{subsection.3.4}\protected@file@percent }
\citation{VGG16implementation}
\@writefile{toc}{\contentsline {section}{\numberline {4}Implementation of the CNN}{27}{section.4}\protected@file@percent }
\newlabel{bigM1Squema}{{4}{28}{Implementation of the CNN}{lstnumber.-9.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Visual representation of the first model.}}{28}{figure.8}\protected@file@percent }
\citation{kerasDocs}
\citation{binnaryCrossentropy}
\citation{learningRates}
\citation{learningRates}
\newlabel{learningRates}{{4}{30}{Implementation of the CNN}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Effects of different learning rates on the learning process of a model. \cite  {learningRates}}}{30}{figure.9}\protected@file@percent }
\citation{RMSprop}
\citation{regularization}
\citation{Vanishing}
\citation{Vanishing}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The Exploding Gradient Problem.}{33}{subsection.4.1}\protected@file@percent }
\newlabel{explodingGradientProblem}{{4.1}{33}{The Exploding Gradient Problem}{subsection.4.1}{}}
\newlabel{SigmoidAndDerivative}{{4.1}{33}{The Exploding Gradient Problem}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Sigmoid function and itÂ´s derivative. \cite  {Vanishing}}}{33}{figure.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The Problem With the Balance of the Data}{36}{subsection.4.2}\protected@file@percent }
\newlabel{problemUnbalanceData}{{4.2}{36}{The Problem With the Balance of the Data}{subsection.4.2}{}}
\newlabel{UnbalancedConfusionMatrix}{{4.2}{37}{The Problem With the Balance of the Data}{lstnumber.-11.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Confusion Matrix for the predictions of the model trained with unbalanced data.}}{37}{figure.11}\protected@file@percent }
\newlabel{UnbalancedTrainDataSet}{{4.2}{38}{The Problem With the Balance of the Data}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Label distribution for the unbalanced train data set.}}{38}{figure.12}\protected@file@percent }
\citation{classWeights}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Implementing Weighted classes with SkLearn}{39}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Stablishing A clasification System Based on the UPDRS}{41}{subsubsection.4.2.2}\protected@file@percent }
\newlabel{UPDRSSumDistribution}{{4.2.2}{42}{Stablishing A clasification System Based on the UPDRS}{subsubsection.4.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Distribution for the sum of the different attributes associated to the UPDRS within the data set.}}{42}{figure.13}\protected@file@percent }
\newlabel{UPDRSSumDistributionClasses}{{4.2.2}{44}{Stablishing A clasification System Based on the UPDRS}{lstnumber.-13.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Distribution for the classes created based of sum of the different attributes associated to the UPDRS within the data set.}}{44}{figure.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{52}{section.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Table with all the results for the trials that have been done over the second model of the multiclass clasification approach.}}{52}{table.1}\protected@file@percent }
\newlabel{MulticlassSecondModelResultTable}{{1}{52}{Table with all the results for the trials that have been done over the second model of the multiclass clasification approach}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Possible Future Work Lines}{54}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Social Implications}{55}{subsection.5.2}\protected@file@percent }
\bibdata{bibliografia.bib}
\bibcite{parkinsonhistoria}{1}
\bibcite{parkinson2002essay}{2}
\bibcite{sveinbjornsdottir2016clinical}{3}
\bibcite{frank2006approach}{4}
\bibcite{synapse}{5}
\bibcite{handsonmachinelearning}{6}
\bibcite{deeplearningygrabaciones}{7}
\bibcite{belic2019artificial}{8}
\bibcite{cnntoformantmeasures}{9}
\bibcite{cortex58}{10}
\bibcite{cortex59}{11}
\bibcite{neocognitron}{12}
\bibcite{VGGinfo}{13}
\bibcite{VGGimg}{14}
\bibcite{normalization}{15}
\bibcite{normalizationTechniques}{16}
\bibcite{datascienceZscore}{17}
\bibcite{normalizeSkLearn}{18}
\bibcite{dateTestsDefs}{19}
\bibcite{VGG16implementation}{20}
\bibcite{learningRates}{21}
\bibcite{kerasDocs}{22}
\bibcite{binnaryCrossentropy}{23}
\bibcite{RMSprop}{24}
\bibcite{regularization}{25}
\bibcite{Vanishing}{26}
\bibcite{classWeights}{27}
\bibstyle{IEEEtran}
\gdef \@abspage@last{59}
